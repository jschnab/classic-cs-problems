{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from math import exp\n",
    "from random import random, shuffle\n",
    "from typing import List, Callable, Optional, TypeVar, Tuple\n",
    "\n",
    "exec('from __future__ import annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(xs: List[float], ys: List[float]) -> float:\n",
    "    return sum(x * y for x, y in zip(xs, ys))\n",
    "\n",
    "def sigmoid(x: float) -> float:\n",
    "    return 1.0 / (1.0 + exp(-x))\n",
    "\n",
    "def derivative_sigmoid(x: float) -> float:\n",
    "    sig: float = sigmoid(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def normalize(dataset: List[List[float]]) -> None:\n",
    "    \"\"\"\n",
    "    Normalize by feature scaling, each columns is scaled between 0 and 1.\n",
    "    Assumes all rows have equal length.\n",
    "    \"\"\"\n",
    "    for col_num in range(len(dataset[0])):\n",
    "        column: List[float] = [row[col_num] for row in dataset]\n",
    "        maxi = max(column)\n",
    "        mini = min(column)\n",
    "        for row_num in range(len(dataset)):\n",
    "            dataset[row_num][col_num] = (dataset[row_num][col_num] - mini) / (maxi - mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(\n",
    "        self,\n",
    "        weights: List[float],\n",
    "        learning_rate: float,\n",
    "        activation_function: Callable[[float], float],\n",
    "        derivative_activation: Callable[[float], float]\n",
    "    ):\n",
    "        self.weights = weights\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation_function = activation_function\n",
    "        self.derivative_activation = derivative_activation\n",
    "        self.output_cache: float = 0.0\n",
    "        self.delta: float = 0.0\n",
    "            \n",
    "    def output(self, inputs: List[float]) -> float:\n",
    "        self.output_cache = dot_product(inputs, self.weights)\n",
    "        return self.activation_function(self.output_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        previous_layer,\n",
    "        num_neurons: int,\n",
    "        learning_rate: float,\n",
    "        activation_function: Callable[[float], float],\n",
    "        derivative_activation: Callable[[float], float]\n",
    "    ):\n",
    "        self.previous_layer = previous_layer\n",
    "        self.neurons: List[Neuron] = []\n",
    "        for i in range(num_neurons):\n",
    "            if not previous_layer:\n",
    "                random_weights: List[float] = []\n",
    "            else:\n",
    "                random_weights = [random() for _ in range(len(previous_layer.neurons))]\n",
    "            neuron = Neuron(random_weights, learning_rate, activation_function, derivative_activation)\n",
    "            self.neurons.append(neuron)\n",
    "        self.output_cache: List[float] = [0.0 for _ in range(num_neurons)]\n",
    "            \n",
    "    def outputs(self, inputs: List[float]) -> List[float]:\n",
    "        if not self.previous_layer:\n",
    "            self.output_cache = inputs\n",
    "        else:\n",
    "            self.output_cache = [n.output(inputs) for n in self.neurons]\n",
    "        return self.output_cache\n",
    "    \n",
    "    def calculate_deltas_output(self, expected: List[float]) -> None:\n",
    "        for n in range(len(self.neurons)):\n",
    "            derivative = self.neurons[n].derivative_activation(self.neurons[n].output_cache)\n",
    "            error = expected[n] - self.output_cache[n]\n",
    "            self.neurons[n].delta = derivative * error\n",
    "    \n",
    "    def calculate_deltas_hidden(self, next_layer) -> None:\n",
    "        for index, neuron in enumerate(self.neurons):\n",
    "            next_weights: List[float] = [n.weights[index] for n in next_layer.neurons]\n",
    "            next_deltas: List[float] = [n.delta for n in next_layer.neurons]\n",
    "            sum_weights_deltas: float = dot_product(next_weights, next_deltas)\n",
    "            neuron.delta = neuron.derivative_activation(neuron.output_cache) * sum_weights_deltas\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar('T')  # output type of interpretation of neural network\n",
    "\n",
    "class Network:\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_structure: List[int],\n",
    "        learning_rate: float,\n",
    "        activation_function: Callable[[float], float]=sigmoid,\n",
    "        derivative_activation: Callable[[float], float]=derivative_sigmoid\n",
    "    ):\n",
    "        if len(layer_structure) < 3:\n",
    "            raise ValueError(f'The network should contain >= 3 layers, got {len(layer_structure)}')\n",
    "        self.layers: List[Layer] = []\n",
    "        input_layer: Layer = Layer(\n",
    "            None,\n",
    "            layer_structure[0],\n",
    "            learning_rate,\n",
    "            activation_function,\n",
    "            derivative_activation)\n",
    "        self.layers.append(input_layer)\n",
    "        for previous, num_neurons in enumerate(layer_structure[1::]):\n",
    "            next_layer = Layer(\n",
    "                self.layers[previous],\n",
    "                num_neurons,\n",
    "                learning_rate,\n",
    "                activation_function,\n",
    "                derivative_activation)\n",
    "            self.layers.append(next_layer)\n",
    "            \n",
    "    def outputs(self, inputs: List[float]) -> List[float]:\n",
    "        \"\"\"Pushes input to the first layer, then output of the first layer as input to the second, etc.\"\"\"\n",
    "        return reduce(lambda inp, layer: layer.outputs(inp), self.layers, inputs)\n",
    "    \n",
    "    def backpropagate(self, expected: List[float]) -> None:\n",
    "        # calculate deltas for output neurons\n",
    "        last_layer: int = len(self.layers) - 1\n",
    "        self.layers[last_layer].calculate_deltas_output(expected)\n",
    "        \n",
    "        # calcuate deltas for hidden layer\n",
    "        for l in range(last_layer - 1, 0, -1):\n",
    "            self.layers[l].calculate_deltas_hidden(self.layers[l + 1])\n",
    "            \n",
    "    def update_weights(self) -> None:\n",
    "        \"\"\"\n",
    "        Update weights using deltas calculated by backpropagate().\n",
    "        \"\"\"\n",
    "        for layer in self.layers[1:]:  # skip input layer\n",
    "            for neuron in layer.neurons:\n",
    "                for w in range(len(neuron.weights)):\n",
    "                    neuron.weights[w] = neuron.weights[w] +\\\n",
    "                        neuron.learning_rate * layer.previous_layer.output_cache[w] * neuron.delta\n",
    "                    \n",
    "    def train(self, inputs: List[List[float]], expecteds: List[List[float]]) -> None:\n",
    "        for locations, xs in enumerate(inputs):\n",
    "            ys: List[float] = expecteds[locations]\n",
    "            outs: List[float] = self.outputs(xs)\n",
    "            self.backpropagate(ys)\n",
    "            self.update_weights()\n",
    "            \n",
    "    def validate(\n",
    "        self,\n",
    "        inputs: List[List[float]],\n",
    "        expected: List[T],\n",
    "        interpret_output: Callable[[List[float]], T]\n",
    "    ) -> Tuple[int, int, float]:\n",
    "\n",
    "        correct = 0\n",
    "\n",
    "        for inp, exp in zip(inputs, expected):\n",
    "            result: T = interpret_output(self.outputs(inp))\n",
    "            if result == exp:\n",
    "                correct += 1\n",
    "\n",
    "        percentage: float = correct / len(inputs)\n",
    "        return correct, len(inputs), percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of flower species using the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the iris dataset\n",
    "# response = requests.get('http://raw.githubusercontent.com/davecom/ClassicComputerScienceProblemsInPython/master/Chapter7/iris.csv')\n",
    "\n",
    "# write the data to disk\n",
    "# with open('iris_dataset.csv', 'w') as f:\n",
    "#     f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_parameters: List[List[float]] = []\n",
    "iris_classifications: List[List[float]] = []\n",
    "iris_species: List[str] = []\n",
    "\n",
    "with open('iris_dataset.csv') as f:\n",
    "    irises: List = list(csv.reader(f))\n",
    "        \n",
    "shuffle(irises)\n",
    "for iris in irises:\n",
    "    parameters: List[float] = list(map(float, iris[:4]))\n",
    "    iris_parameters.append(parameters)\n",
    "    species: str = iris[4]\n",
    "    iris_species.append(species)\n",
    "    if species == 'Iris-setosa':\n",
    "        iris_classifications.append([1.0, 0.0, 0.0])\n",
    "    elif species == 'Iris-versicolor':\n",
    "        iris_classifications.append([0.0, 1.0, 0.0])\n",
    "    else:\n",
    "        iris_classifications.append([0.0, 0.0, 1.0])\n",
    "\n",
    "normalize(iris_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_interpret_output(output: List[float]) -> str:\n",
    "    if max(output) == output[0]:\n",
    "        return 'Iris-setosa'\n",
    "    elif max(output) == output[1]:\n",
    "        return 'Iris-versicolor'\n",
    "    else:\n",
    "        return 'Iris-virginica'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_network: Network = Network([4, 6, 3], 0.3)\n",
    "\n",
    "iris_trainers: List[List[float]] = iris_parameters[:140]\n",
    "iris_correct: List[List[float]] = iris_classifications[:140]\n",
    "for _ in range(50):\n",
    "    iris_network.train(iris_trainers, iris_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 correct of 10 = 100.00\n"
     ]
    }
   ],
   "source": [
    "iris_testers: List[List[float]] = iris_parameters[140:150]\n",
    "iris_testers_correct: List[List[float]] = iris_species[140:150]\n",
    "iris_results = iris_network.validate(iris_testers, iris_testers_correct, iris_interpret_output)\n",
    "print(f\"{iris_results[0]} correct of {iris_results[1]} = {iris_results[2] * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "# response = urllib.request.urlopen('http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data')\n",
    "# with open('wine.csv', 'w') as f:\n",
    "#     f.write(response.read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine_interpret_output(output: List[float]) -> int:\n",
    "    if max(output) == output[0]:\n",
    "        return 1\n",
    "    elif max(output) == output[1]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wine.csv') as f:\n",
    "    wine_data = list(csv.reader(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 correct out of 28 = 100.00%\n"
     ]
    }
   ],
   "source": [
    "shuffle(wine_data)\n",
    "\n",
    "wine_parameters: List[List[float]] = []\n",
    "wine_classifications: List[List[float]] = []\n",
    "wine_type: List[int] = []\n",
    "    \n",
    "for row in wine_data:\n",
    "    wine_parameters.append(list(map(float, row[1:])))\n",
    "    if row[0] == '1':\n",
    "        wine_classifications.append([1.0, 0.0, 0.0])\n",
    "    elif row[0] == '2':\n",
    "        wine_classifications.append([0.0, 1.0, 0.0])\n",
    "    else:\n",
    "        wine_classifications.append([0.0, 0.0, 1.0])\n",
    "    wine_type.append(int(row[0]))\n",
    "    \n",
    "normalize(wine_parameters)\n",
    "    \n",
    "wine_network: Network = Network([13, 13, 3], learning_rate=0.9)\n",
    "    \n",
    "wine_trainers: List[List[float]] = wine_parameters[:150]\n",
    "wine_trainers_correct: List[List[float]] = wine_classifications[:150]\n",
    "for _ in range(50):\n",
    "    wine_network.train(wine_trainers, wine_trainers_correct)\n",
    "    \n",
    "wine_testers: List[List[float]] = wine_parameters[150:]\n",
    "wine_testers_correct: List[List[float]] = wine_type[150:]\n",
    "wine_results = wine_network.validate(wine_testers, wine_testers_correct, wine_interpret_output)\n",
    "print(f\"{wine_results[0]} correct out of {wine_results[1]} = {wine_results[2] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
